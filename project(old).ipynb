{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oOUc1qi91oq"
   },
   "source": [
    "Ceci n'est pas un commentaire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lx4jEs_D3ATI"
   },
   "source": [
    "# ***Google Captcha image recognition***\n",
    "**A Deep Learning Project using TensorFlow**\n",
    "\n",
    "*by Emma Begard, Augustin Bouveau, Bagin Jobert-Rollin, Hugues Boisdon*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I Data **Fetching**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our source Dataset can be found at : *https://www.kaggle.com/datasets/mikhailma/test-dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*credits : **Mike Mazurov***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1 **Dowloading** Data Files from ***KaggleHub*** Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFMAVdi34rRi",
    "outputId": "04b8fd29-b158-4cd8-a1f6-f691de58d0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files in cache: C:\\Users\\Development\\.cache\\kagglehub\\datasets\\mikhailma\\test-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "DATA_FOLDER_PATH_IF_CACHED = kagglehub.dataset_download(\"mikhailma/test-dataset\")\n",
    "print(\"Path to dataset files in cache:\", DATA_FOLDER_PATH_IF_CACHED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data files are downloaded in the Users **cache** by default.\n",
    "If the data source folder is moved, ***please update*** the following *path variable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_PATH_IF_MOVED = \"\" # Data folder path if data was moved since download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2 **Loading** Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.A *Functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def loadImagesFromDirectory(directoryPath:str) -> pd.DataFrame:\n",
    "    data: dict[str:list] = {\"Image\": [], \"Label\": []}\n",
    "    \n",
    "    for root, directories, files in os.walk(directoryPath):\n",
    "        for f in files:\n",
    "            subFolderName = f.split(\" \")[0]\n",
    "            if subFolderName == \"Cross\"  : subFolderName = \"Crosswalk\"\n",
    "            if subFolderName == \"Tlight\" : subFolderName = \"Traffic Light\"\n",
    "\n",
    "            data[\"Image\"].append(Image.open(directoryPath+ \"/\" + subFolderName + \"/\"+ f).convert(\"RGB\"))\n",
    "            data[\"Label\"].append(subFolderName)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.2.B Loading **raw** image data in a *Dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=120x120 a...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=120x120 a...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=120x120 a...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=120x120 a...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=120x120 a...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image    Label\n",
       "0  <PIL.Image.Image image mode=RGB size=120x120 a...  Bicycle\n",
       "1  <PIL.Image.Image image mode=RGB size=120x120 a...  Bicycle\n",
       "2  <PIL.Image.Image image mode=RGB size=120x120 a...  Bicycle\n",
       "3  <PIL.Image.Image image mode=RGB size=120x120 a...  Bicycle\n",
       "4  <PIL.Image.Image image mode=RGB size=120x120 a...  Bicycle"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgFolderPath = DATA_FOLDER_PATH_IF_CACHED+\"/Google_Recaptcha_V2_Images_Dataset/images\" if DATA_FOLDER_PATH_IF_MOVED == \"\" else DATA_FOLDER_PATH_IF_MOVED+\"/Google_Recaptcha_V2_Images_Dataset/images\"\n",
    "\n",
    "rawImagesDf = loadImagesFromDirectory(imgFolderPath)\n",
    "rawImagesDf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we have loaded data in a *pandas Dataframe*, with images as *Image* (class from PIL library)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II Data **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1 **Cleaning** Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.A *Images Size* Normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### II.1.A.a Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkImagesSizeInDataframe(df:pd.DataFrame) -> None:\n",
    "    sizeCounts = {}\n",
    "    for image in df[\"Image\"]:\n",
    "        if not(image.size in sizeCounts):\n",
    "            sizeCounts[image.size] = 1\n",
    "        else :\n",
    "            sizeCounts[image.size] += 1\n",
    "    print(f\"Sizes found in Dataframe : {sizeCounts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "from copy import deepcopy\n",
    "\n",
    "def normalizeImageSizes(df:pd.DataFrame, imgTargetSize:tuple[int,int] = (120, 120)) -> pd.DataFrame:\n",
    "    dataframe = deepcopy(df)\n",
    "    numOfCropped = 0; numOfExpandeds = 0\n",
    "    for index, row in dataframe.iterrows():\n",
    "        width  = row[\"Image\"].width\n",
    "        height = row[\"Image\"].height\n",
    "        \n",
    "        noPaddings  = [0   , 0  ,     0,      0]\n",
    "        noCroppings = [0   , 0  , width, height]\n",
    "                    #  Left, Top, Right, Bottom\n",
    "        \n",
    "        paddings  = deepcopy(noPaddings)\n",
    "        croppings = deepcopy(noCroppings)\n",
    "        \n",
    "        if width < imgTargetSize[0]:\n",
    "            pixelsToAdd = imgTargetSize[0] - width\n",
    "            paddings[0] = pixelsToAdd  // 2\n",
    "            paddings[2] = (pixelsToAdd - pixelsToAdd  // 2)\n",
    "        elif width > imgTargetSize[0]:\n",
    "            pixelsToCrop = width - imgTargetSize[0]\n",
    "            croppings[0] = pixelsToCrop // 2\n",
    "            croppings[2] = width - (pixelsToCrop-pixelsToCrop // 2)\n",
    "        \n",
    "        if height < imgTargetSize[1]:\n",
    "            pixelsToAdd = imgTargetSize[1] - height\n",
    "            paddings[1] = pixelsToAdd  // 2\n",
    "            paddings[3] = (pixelsToAdd - pixelsToAdd  // 2)\n",
    "        elif height > imgTargetSize[1]:\n",
    "            pixelsToCrop = height - imgTargetSize[1]\n",
    "            croppings[1] = pixelsToCrop // 2\n",
    "            croppings[3] = height - (pixelsToCrop-pixelsToCrop // 2)\n",
    "        \n",
    "        if paddings != noPaddings:\n",
    "            row[\"Image\"] = ImageOps.expand(row[\"Image\"], border=tuple(paddings), fill='black')\n",
    "            numOfExpandeds += 1\n",
    "        if croppings != noCroppings:\n",
    "            row[\"Image\"] = ImageOps.crop(row[\"Image\"], border=tuple(paddings))\n",
    "            numOfCropped += 1\n",
    "    print(f\"{numOfCropped} images were cropped to {imgTargetSize}!\")\n",
    "    print(f\"{numOfExpandeds} images were expanded to {imgTargetSize}!\")\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### II.1.A.b Normalizing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes found in Dataframe : {(120, 120): 10705, (100, 100): 1025}\n",
      "0 images were cropped to (120, 120)!\n",
      "1025 images were expanded to (120, 120)!\n",
      "Sizes found in Dataframe : {(120, 120): 11730}\n"
     ]
    }
   ],
   "source": [
    "# Initial Check\n",
    "checkImagesSizeInDataframe(rawImagesDf)\n",
    "\n",
    "normalizedSizeImagesDf = normalizeImageSizes(rawImagesDf)\n",
    "\n",
    "# Final Check\n",
    "checkImagesSizeInDataframe(normalizedSizeImagesDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now assured to work only with images of size *(120px per 120px)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.B Transforming Images to *pixel value Arrays*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "def imagesToPixelArrays(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    dataframe = deepcopy(df)\n",
    "    for id, row in dataframe.iterrows():\n",
    "        row[\"Image\"] = np.array(row[\"Image\"]).astype(np.float32)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[117.0, 114.0, 104.0], [114.0, 110.0, 101.0]...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[54.0, 75.0, 67.0], [58.0, 76.0, 69.0], [66....</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[38.0, 33.0, 27.0], [37.0, 34.0, 28.0], [37....</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[49.0, 49.0, 51.0], [55.0, 56.0, 58.0], [72....</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[135.0, 128.0, 125.0], [143.0, 130.0, 129.0]...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image    Label\n",
       "0  [[[117.0, 114.0, 104.0], [114.0, 110.0, 101.0]...  Bicycle\n",
       "1  [[[54.0, 75.0, 67.0], [58.0, 76.0, 69.0], [66....  Bicycle\n",
       "2  [[[38.0, 33.0, 27.0], [37.0, 34.0, 28.0], [37....  Bicycle\n",
       "3  [[[49.0, 49.0, 51.0], [55.0, 56.0, 58.0], [72....  Bicycle\n",
       "4  [[[135.0, 128.0, 125.0], [143.0, 130.0, 129.0]...  Bicycle"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixelArraysDf = imagesToPixelArrays(normalizedSizeImagesDf)\n",
    "\n",
    "pixelArraysDf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pursue the preprocessing with a more readable and usable data format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.1.C *Pixel values* Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizePixelValues(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    dataframe = deepcopy(df)\n",
    "    for id, row in dataframe.iterrows():\n",
    "        row[\"Image\"] /= 255\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.45882353, 0.44705883, 0.40784314], [0.447...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0.21176471, 0.29411766, 0.2627451], [0.2274...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0.14901961, 0.12941177, 0.105882354], [0.14...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0.19215687, 0.19215687, 0.2], [0.21568628, ...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0.5294118, 0.5019608, 0.49019608], [0.56078...</td>\n",
       "      <td>Bicycle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Image    Label\n",
       "0  [[[0.45882353, 0.44705883, 0.40784314], [0.447...  Bicycle\n",
       "1  [[[0.21176471, 0.29411766, 0.2627451], [0.2274...  Bicycle\n",
       "2  [[[0.14901961, 0.12941177, 0.105882354], [0.14...  Bicycle\n",
       "3  [[[0.19215687, 0.19215687, 0.2], [0.21568628, ...  Bicycle\n",
       "4  [[[0.5294118, 0.5019608, 0.49019608], [0.56078...  Bicycle"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizedPixelArraysDf = normalizePixelValues(pixelArraysDf)\n",
    "\n",
    "normalizedPixelArraysDf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixel values are now normalized from **0 to 1** instead of **0 to 255**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 Preparing Data for Tensorflow use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "features = np.stack(normalizedPixelArraysDf[\"Image\"].values)\n",
    "labels   = np.array(normalizedPixelArraysDf[\"Label\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3 *Splitting* Data in 2 Datasets for Training and Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 120\n",
    "img_width = 120\n",
    "\n",
    "features_train, features_val, labels_train, labels_val = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((features_train, labels_train))\n",
    "val_ds   = tf.data.Dataset.from_tensor_slices((features_val,     labels_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III **Designing** the *Model*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
